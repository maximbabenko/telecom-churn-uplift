# Customer Churn & Uplift

Проект про предсказание оттока клиентов и оценку эффекта маркетинговых воздействий (uplift).  
Цель: **научиться находить клиентов с риском оттока** и **понять, кому рассылка/оффер реально помогает**, а кому — нет.

## Датасет

В проекте использован открытый набор **Orange Telecom (Belgium) Customer churn** с [OpenML](https://www.openml.org/d/42178).  
Это реальный анонимизированный датасет телеком-оператора, где:

- `churn` — целевая переменная (1 = клиент ушёл, 0 = остался).  
- `treatment` — бинарный индикатор воздействия (например, предложенная акция/оффер).  
- `PC1…PC177` — обезличенные признаки (поведение клиентов, usage, доход, сегменты).  

Особенности:
- **~12k клиентов**,  
- **~177 признаков (PC-фичи + категориальные FACTOR)**,  
- сильный **дисбаланс классов**: churn ≈ 3–4%.  

Почему интересно: кроме классического churn, здесь можно проверить uplift-моделирование (оценить эффект маркетинга).

## Задача

1) **Классический churn**: бинарная классификация (`churn=1/0`).  
2) **Uplift-моделирование**: оценка каузального эффекта воздействия (`treatment=1/0`) на отток.

### Бизнес-смысл
- Модель churn позволяет заранее увидеть, кто «горит» → успеть удержать.
- Uplift показывает, **кого стоит таргетить** (эффект положительный) и **кого трогать не надо** (эффект нулевой/отрицательный).

## Структура проекта
```text
.
├── data/
│   ├── raw/                 # исходные данные (CSV/Parquet + std.)
│   └── processed/           # препроцесс, слипы, y*, *.npy
├── notebooks/
│   ├── EDA.ipynb            # разведочный анализ
│   ├── processed.ipynb      # чистка/препроцесс/слипы
│   ├── modeling.ipynb       # базовые и баланс. модели churn
│   ├── lgbm_tuned.ipynb     # тюнинг LGBM 
│   └── uplift.ipynb         # uplift-модели (CT, TwoModels) 
├── reports/
│   ├── figures/             # все картинки из ноутбуков
│   └── eda_summary.csv      # сводка по фичам
├── src/
│   ├── data/
│   │   └── load_openml.py   # загрузка из OpenML
│   │   └── standardize_columns.py  # приведение колонок churn/treatment
├── requirements.txt
└── README.md
```
.
|-- data/
|   |-- raw/                 # исходные данные
|   `-- processed/           # препроцесс
|-- notebooks/
|   |-- EDA.ipynb            # анализ
|   |-- processed.ipynb      # чистка/препроцесс
|   |-- modeling.ipynb       # базовые модели
|   |-- lgbm_tuned.ipynb     # тининг LGBM
|   `-- uplift.ipynb         # uplifr-модели
|-- reports/
|   |-- figures/
|   `-- eda_summary.csv
|-- src/
|   |-- data/
|   |   `-- load_openml.py   # загрузка датасета
|   |   `-- standardize_columns.py   # приведение колонок churn\treatment  
|-- requirements.txt
`-- README.md


## Технологии

- Python, NumPy, Pandas, Matplotlib/Seaborn, Scikit-learn  
- LightGBM, Imbalanced-learn  
- Scikit-uplift (модели + метрики uplift)

## Ключевые находки EDA

- Класс 1 (churn) сильно редкий: ≈3–4%.
- Прямых сильных корреляций с таргетом нет (топовые признаки ~0.03–0.05) → задача сложная, сигнал слабый.
- Мультиколлинеарности среди топ-фич почти нет (корреляции между признаками низкие).

## Моделирование churn

### Мы пробовали:

- Логистическую регрессию, RandomForest, LightGBM.
- Балансировки: class_weight=balanced, RandomUnderSampler, SMOTE/SMOTEENN.
- Подбор порога по F1 для класса 1.

### Пример итоговых метрик (валид/тест)

- ROC-AUC ~ 0.83–0.85
- PR-AUC ~ 0.17–0.21
- F1(1) ~ 0.20–0.25 (при подборе порога)

Для дисбалансных задач это нормальные цифры. Главная рабочая метрика — PR-AUC (качество по редкому классу).

## Uplift-моделирование

### Модели:

- Class Transformation (CT) — одна модель бустинга.
- TwoModels (T-learner) — два бустинга: на treatment и на control.

### Метрики:

- Qini AUC — интегральная метрика uplift (как ROC-AUC, только для каузального эффекта).
- uplift@k (5/10/20%) — полезна, если есть бюджет на топ-k% клиентов.

### Графики:

- Qini-кривые (кумулятивный инкремент по мере «накрытия» аудитории).
- Uplift by deciles — uplift по десятым долям (1-й дециль = самые «перспективные» по прогнозу).

### Результаты (на тесте):

- Qini AUC близок к 0 (иногда чуть отрицателен).
- uplift@k колеблется, стабильного плюса нет.
- Qini-кривые «гуляют» вокруг нуля, uplift по децилям нестабилен.

Вывод: глобального эффекта воздействия нет (по EDA — разница ~−0.28% и статистически незначима).
Тем не менее, встречаются отдельные децили с позитивным uplift → их можно использовать как наметку для таргетинга.

## Что это значит для бизнеса?

1. При таком дисбалансе и слабом сигнале даже +несколько десятков TP на 1000 клиентов — уже деньги (меньше оттока, меньше затрат на повторное привлечение).
2. Uplift сейчас «сырое» место: лучше не таргетить всю базу, а тестировать верхние децили, где наблюдается положительный эффект.

## Что ещё сделать (перспективы):

- Feature engineering: временные признаки, агрегаты по действиям/доходам/сегментам, интерэкции.
- Сегментация: кластеризация + отдельные модели по сегментам.
- Propensity weighting (IPW): если назначение treatment было нерандомным — добавить модель P(T=1|X) и веса.
- Гипертюнинг бустингов (Optuna) + калибровка вероятностей.
- Бизнес-валидация: A/B или holdout на реальном таргетинге топ-10% по uplift.
